{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "478b0524",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e912988",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8baac96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da18c004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Maths</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Chemistry</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>27</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72</td>\n",
       "      <td>82</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>97</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Maths  Physics  Chemistry  Result\n",
       "0     17       27         22       0\n",
       "1     72       82         77       1\n",
       "2     97       18         13       0\n",
       "3      8       42         37       0\n",
       "4     32       25         20       0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Student_marks.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae2869dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "220149ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, 0:-1]\n",
    "y = data.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dc75ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cafd7a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6f6b401",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 3\n",
    "hidden_size = 60\n",
    "num_classes = 1\n",
    "batch_size = 10\n",
    "num_epochs = 50\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6da6628c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Traindata(Dataset):\n",
    "    def __init__(self, X_tensor, y_tensor):\n",
    "        self.X =X_tensor\n",
    "        self.y = y_tensor\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return (self.X[index], self.y[index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "train_data = Traindata(torch.FloatTensor(X_train), \n",
    "                       torch.FloatTensor(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4371b843",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.to_numpy(dtype= 'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edf1ad26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Testdata(Dataset):\n",
    "    def __init__(self, X_tensor, y_tensor):\n",
    "        self.X =X_tensor\n",
    "        self.y = y_tensor\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return (self.X[index], self.y[index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "test_data = Testdata(torch.FloatTensor(X_test),\n",
    "                     torch.FloatTensor(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "036ea4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset = train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_data, batch_size=batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1b1a99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "  \n",
    "    def forward(self,x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa68f084",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55ec5fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], step[20/80], loss: 0.6736\n",
      "Epoch [1/50], step[40/80], loss: 0.5824\n",
      "Epoch [1/50], step[60/80], loss: 0.5322\n",
      "Epoch [1/50], step[80/80], loss: 0.4795\n",
      "Epoch [2/50], step[20/80], loss: 0.5274\n",
      "Epoch [2/50], step[40/80], loss: 0.3874\n",
      "Epoch [2/50], step[60/80], loss: 0.4303\n",
      "Epoch [2/50], step[80/80], loss: 0.2509\n",
      "Epoch [3/50], step[20/80], loss: 0.4179\n",
      "Epoch [3/50], step[40/80], loss: 0.1846\n",
      "Epoch [3/50], step[60/80], loss: 0.2920\n",
      "Epoch [3/50], step[80/80], loss: 0.2709\n",
      "Epoch [4/50], step[20/80], loss: 0.4243\n",
      "Epoch [4/50], step[40/80], loss: 0.2454\n",
      "Epoch [4/50], step[60/80], loss: 0.1962\n",
      "Epoch [4/50], step[80/80], loss: 0.3931\n",
      "Epoch [5/50], step[20/80], loss: 0.3725\n",
      "Epoch [5/50], step[40/80], loss: 0.4685\n",
      "Epoch [5/50], step[60/80], loss: 0.1824\n",
      "Epoch [5/50], step[80/80], loss: 0.3097\n",
      "Epoch [6/50], step[20/80], loss: 0.1580\n",
      "Epoch [6/50], step[40/80], loss: 0.1659\n",
      "Epoch [6/50], step[60/80], loss: 0.3024\n",
      "Epoch [6/50], step[80/80], loss: 0.3985\n",
      "Epoch [7/50], step[20/80], loss: 0.0757\n",
      "Epoch [7/50], step[40/80], loss: 0.1083\n",
      "Epoch [7/50], step[60/80], loss: 0.1436\n",
      "Epoch [7/50], step[80/80], loss: 0.3396\n",
      "Epoch [8/50], step[20/80], loss: 0.1651\n",
      "Epoch [8/50], step[40/80], loss: 0.1584\n",
      "Epoch [8/50], step[60/80], loss: 0.2320\n",
      "Epoch [8/50], step[80/80], loss: 0.4743\n",
      "Epoch [9/50], step[20/80], loss: 0.2350\n",
      "Epoch [9/50], step[40/80], loss: 0.4905\n",
      "Epoch [9/50], step[60/80], loss: 0.3277\n",
      "Epoch [9/50], step[80/80], loss: 0.1774\n",
      "Epoch [10/50], step[20/80], loss: 0.0549\n",
      "Epoch [10/50], step[40/80], loss: 0.1260\n",
      "Epoch [10/50], step[60/80], loss: 0.0666\n",
      "Epoch [10/50], step[80/80], loss: 0.1689\n",
      "Epoch [11/50], step[20/80], loss: 0.2741\n",
      "Epoch [11/50], step[40/80], loss: 0.1782\n",
      "Epoch [11/50], step[60/80], loss: 0.0361\n",
      "Epoch [11/50], step[80/80], loss: 0.1148\n",
      "Epoch [12/50], step[20/80], loss: 0.1883\n",
      "Epoch [12/50], step[40/80], loss: 0.0962\n",
      "Epoch [12/50], step[60/80], loss: 0.2436\n",
      "Epoch [12/50], step[80/80], loss: 0.1274\n",
      "Epoch [13/50], step[20/80], loss: 0.2121\n",
      "Epoch [13/50], step[40/80], loss: 0.1660\n",
      "Epoch [13/50], step[60/80], loss: 0.0860\n",
      "Epoch [13/50], step[80/80], loss: 0.3956\n",
      "Epoch [14/50], step[20/80], loss: 0.3479\n",
      "Epoch [14/50], step[40/80], loss: 0.0400\n",
      "Epoch [14/50], step[60/80], loss: 0.1396\n",
      "Epoch [14/50], step[80/80], loss: 0.0491\n",
      "Epoch [15/50], step[20/80], loss: 0.0756\n",
      "Epoch [15/50], step[40/80], loss: 0.2055\n",
      "Epoch [15/50], step[60/80], loss: 0.1696\n",
      "Epoch [15/50], step[80/80], loss: 0.0108\n",
      "Epoch [16/50], step[20/80], loss: 0.0731\n",
      "Epoch [16/50], step[40/80], loss: 0.1143\n",
      "Epoch [16/50], step[60/80], loss: 0.2097\n",
      "Epoch [16/50], step[80/80], loss: 0.0639\n",
      "Epoch [17/50], step[20/80], loss: 0.1128\n",
      "Epoch [17/50], step[40/80], loss: 0.3229\n",
      "Epoch [17/50], step[60/80], loss: 0.0699\n",
      "Epoch [17/50], step[80/80], loss: 0.0275\n",
      "Epoch [18/50], step[20/80], loss: 0.2542\n",
      "Epoch [18/50], step[40/80], loss: 0.1267\n",
      "Epoch [18/50], step[60/80], loss: 0.2286\n",
      "Epoch [18/50], step[80/80], loss: 0.0571\n",
      "Epoch [19/50], step[20/80], loss: 0.1289\n",
      "Epoch [19/50], step[40/80], loss: 0.1318\n",
      "Epoch [19/50], step[60/80], loss: 0.1235\n",
      "Epoch [19/50], step[80/80], loss: 0.2140\n",
      "Epoch [20/50], step[20/80], loss: 0.0996\n",
      "Epoch [20/50], step[40/80], loss: 0.0616\n",
      "Epoch [20/50], step[60/80], loss: 0.0651\n",
      "Epoch [20/50], step[80/80], loss: 0.0736\n",
      "Epoch [21/50], step[20/80], loss: 0.0627\n",
      "Epoch [21/50], step[40/80], loss: 0.1318\n",
      "Epoch [21/50], step[60/80], loss: 0.1154\n",
      "Epoch [21/50], step[80/80], loss: 0.0823\n",
      "Epoch [22/50], step[20/80], loss: 0.0704\n",
      "Epoch [22/50], step[40/80], loss: 0.0308\n",
      "Epoch [22/50], step[60/80], loss: 0.1687\n",
      "Epoch [22/50], step[80/80], loss: 0.0181\n",
      "Epoch [23/50], step[20/80], loss: 0.0432\n",
      "Epoch [23/50], step[40/80], loss: 0.0284\n",
      "Epoch [23/50], step[60/80], loss: 0.0300\n",
      "Epoch [23/50], step[80/80], loss: 0.0909\n",
      "Epoch [24/50], step[20/80], loss: 0.0093\n",
      "Epoch [24/50], step[40/80], loss: 0.1392\n",
      "Epoch [24/50], step[60/80], loss: 0.1317\n",
      "Epoch [24/50], step[80/80], loss: 0.0633\n",
      "Epoch [25/50], step[20/80], loss: 0.1026\n",
      "Epoch [25/50], step[40/80], loss: 0.0690\n",
      "Epoch [25/50], step[60/80], loss: 0.1969\n",
      "Epoch [25/50], step[80/80], loss: 0.0627\n",
      "Epoch [26/50], step[20/80], loss: 0.1586\n",
      "Epoch [26/50], step[40/80], loss: 0.3452\n",
      "Epoch [26/50], step[60/80], loss: 0.1297\n",
      "Epoch [26/50], step[80/80], loss: 0.0996\n",
      "Epoch [27/50], step[20/80], loss: 0.1037\n",
      "Epoch [27/50], step[40/80], loss: 0.0065\n",
      "Epoch [27/50], step[60/80], loss: 0.0571\n",
      "Epoch [27/50], step[80/80], loss: 0.1284\n",
      "Epoch [28/50], step[20/80], loss: 0.2073\n",
      "Epoch [28/50], step[40/80], loss: 0.0810\n",
      "Epoch [28/50], step[60/80], loss: 0.1587\n",
      "Epoch [28/50], step[80/80], loss: 0.0780\n",
      "Epoch [29/50], step[20/80], loss: 0.0964\n",
      "Epoch [29/50], step[40/80], loss: 0.1104\n",
      "Epoch [29/50], step[60/80], loss: 0.1143\n",
      "Epoch [29/50], step[80/80], loss: 0.1064\n",
      "Epoch [30/50], step[20/80], loss: 0.0312\n",
      "Epoch [30/50], step[40/80], loss: 0.1051\n",
      "Epoch [30/50], step[60/80], loss: 0.1868\n",
      "Epoch [30/50], step[80/80], loss: 0.0040\n",
      "Epoch [31/50], step[20/80], loss: 0.0338\n",
      "Epoch [31/50], step[40/80], loss: 0.0919\n",
      "Epoch [31/50], step[60/80], loss: 0.0700\n",
      "Epoch [31/50], step[80/80], loss: 0.1561\n",
      "Epoch [32/50], step[20/80], loss: 0.1716\n",
      "Epoch [32/50], step[40/80], loss: 0.1676\n",
      "Epoch [32/50], step[60/80], loss: 0.0056\n",
      "Epoch [32/50], step[80/80], loss: 0.2241\n",
      "Epoch [33/50], step[20/80], loss: 0.0096\n",
      "Epoch [33/50], step[40/80], loss: 0.1543\n",
      "Epoch [33/50], step[60/80], loss: 0.1558\n",
      "Epoch [33/50], step[80/80], loss: 0.0147\n",
      "Epoch [34/50], step[20/80], loss: 0.1201\n",
      "Epoch [34/50], step[40/80], loss: 0.1228\n",
      "Epoch [34/50], step[60/80], loss: 0.0837\n",
      "Epoch [34/50], step[80/80], loss: 0.0467\n",
      "Epoch [35/50], step[20/80], loss: 0.0044\n",
      "Epoch [35/50], step[40/80], loss: 0.0904\n",
      "Epoch [35/50], step[60/80], loss: 0.1080\n",
      "Epoch [35/50], step[80/80], loss: 0.0218\n",
      "Epoch [36/50], step[20/80], loss: 0.1313\n",
      "Epoch [36/50], step[40/80], loss: 0.0198\n",
      "Epoch [36/50], step[60/80], loss: 0.0918\n",
      "Epoch [36/50], step[80/80], loss: 0.0714\n",
      "Epoch [37/50], step[20/80], loss: 0.1799\n",
      "Epoch [37/50], step[40/80], loss: 0.0998\n",
      "Epoch [37/50], step[60/80], loss: 0.0619\n",
      "Epoch [37/50], step[80/80], loss: 0.1189\n",
      "Epoch [38/50], step[20/80], loss: 0.0709\n",
      "Epoch [38/50], step[40/80], loss: 0.0618\n",
      "Epoch [38/50], step[60/80], loss: 0.0027\n",
      "Epoch [38/50], step[80/80], loss: 0.1074\n",
      "Epoch [39/50], step[20/80], loss: 0.0383\n",
      "Epoch [39/50], step[40/80], loss: 0.0474\n",
      "Epoch [39/50], step[60/80], loss: 0.0495\n",
      "Epoch [39/50], step[80/80], loss: 0.0428\n",
      "Epoch [40/50], step[20/80], loss: 0.0141\n",
      "Epoch [40/50], step[40/80], loss: 0.0365\n",
      "Epoch [40/50], step[60/80], loss: 0.0626\n",
      "Epoch [40/50], step[80/80], loss: 0.1212\n",
      "Epoch [41/50], step[20/80], loss: 0.1019\n",
      "Epoch [41/50], step[40/80], loss: 0.1639\n",
      "Epoch [41/50], step[60/80], loss: 0.0671\n",
      "Epoch [41/50], step[80/80], loss: 0.0791\n",
      "Epoch [42/50], step[20/80], loss: 0.1052\n",
      "Epoch [42/50], step[40/80], loss: 0.0920\n",
      "Epoch [42/50], step[60/80], loss: 0.0622\n",
      "Epoch [42/50], step[80/80], loss: 0.0470\n",
      "Epoch [43/50], step[20/80], loss: 0.0407\n",
      "Epoch [43/50], step[40/80], loss: 0.0630\n",
      "Epoch [43/50], step[60/80], loss: 0.0025\n",
      "Epoch [43/50], step[80/80], loss: 0.1070\n",
      "Epoch [44/50], step[20/80], loss: 0.0441\n",
      "Epoch [44/50], step[40/80], loss: 0.0621\n",
      "Epoch [44/50], step[60/80], loss: 0.0284\n",
      "Epoch [44/50], step[80/80], loss: 0.1561\n",
      "Epoch [45/50], step[20/80], loss: 0.0247\n",
      "Epoch [45/50], step[40/80], loss: 0.0656\n",
      "Epoch [45/50], step[60/80], loss: 0.0016\n",
      "Epoch [45/50], step[80/80], loss: 0.1072\n",
      "Epoch [46/50], step[20/80], loss: 0.0831\n",
      "Epoch [46/50], step[40/80], loss: 0.0167\n",
      "Epoch [46/50], step[60/80], loss: 0.0256\n",
      "Epoch [46/50], step[80/80], loss: 0.0096\n",
      "Epoch [47/50], step[20/80], loss: 0.0314\n",
      "Epoch [47/50], step[40/80], loss: 0.1181\n",
      "Epoch [47/50], step[60/80], loss: 0.0103\n",
      "Epoch [47/50], step[80/80], loss: 0.0949\n",
      "Epoch [48/50], step[20/80], loss: 0.1079\n",
      "Epoch [48/50], step[40/80], loss: 0.0205\n",
      "Epoch [48/50], step[60/80], loss: 0.0240\n",
      "Epoch [48/50], step[80/80], loss: 0.0002\n",
      "Epoch [49/50], step[20/80], loss: 0.0964\n",
      "Epoch [49/50], step[40/80], loss: 0.0874\n",
      "Epoch [49/50], step[60/80], loss: 0.1708\n",
      "Epoch [49/50], step[80/80], loss: 0.0148\n",
      "Epoch [50/50], step[20/80], loss: 0.0395\n",
      "Epoch [50/50], step[40/80], loss: 0.0949\n",
      "Epoch [50/50], step[60/80], loss: 0.0021\n",
      "Epoch [50/50], step[80/80], loss: 0.0478\n"
     ]
    }
   ],
   "source": [
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i,(X_train, y_train) in enumerate(train_loader):\n",
    "        X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "        \n",
    "        \n",
    "        # Forward Pass\n",
    "        y_pred = model(X_train)\n",
    "        loss = criterion(y_pred, y_train.unsqueeze(1))\n",
    "\n",
    "        #Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if(i+1) % 20 ==0:\n",
    "            print('Epoch [{}/{}], step[{}/{}], loss: {:.4f}'.format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ae83614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of network: 72.5%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct=0\n",
    "    total=0\n",
    "    for X_test, y_test in test_loader:\n",
    "        X_test = X_test.to(device)\n",
    "        y_test = y_test.to(device)\n",
    "        outputs = model(X_test)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total+= y_test.shape[0]\n",
    "        correct+= (predicted ==y_test).sum().item()\n",
    "        \n",
    "    print('Accuracy of network: {}%'.format(100*correct/total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
